#!/usr/bin/env python3
"""
ğŸš€ 2025å¹´1æœˆæœ€æ–° - ç©¶æ¥µã®Threadsè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ 
æœ€æ–°æƒ…å ±ã«åŸºã¥ãé™ç•Œã‚’è¶…ãˆãŸçœŸã®æœ€é©è§£
"""

import os
import json
import asyncio
import time
import sqlite3
import requests
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
import pandas as pd
from pathlib import Path
import webbrowser
import subprocess
import threading
from http.server import HTTPServer, BaseHTTPRequestHandler
import logging

# 2025å¹´æœ€æ–°ã®AIæŠ€è¡“çµ±åˆ
try:
    from anthropic import Anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class ThreadsPost2025:
    """2025å¹´æœ€é©åŒ–æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿"""
    content: str
    optimal_time: datetime
    ai_confidence: float  # AIç”Ÿæˆã®ä¿¡é ¼åº¦
    engagement_prediction: float  # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬
    revenue_potential: float  # åç›Šãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«
    hashtags: List[str]
    trend_alignment: float  # ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ã®ä¸€è‡´åº¦
    viral_probability: float  # ãƒã‚¤ãƒ©ãƒ«ç¢ºç‡

class AI_ContentEngine2025:
    """2025å¹´æœ€æ–°AIæ­è¼‰ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚¨ãƒ³ã‚¸ãƒ³"""
    
    def __init__(self):
        self.anthropic_client = None
        self.openai_client = None
        self.setup_ai_clients()
        
        # 2025å¹´1æœˆæœ€æ–°ã®ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿
        self.trending_topics = [
            {"topic": "AIåŠ¹ç‡åŒ–", "weight": 0.95, "keywords": ["AI", "è‡ªå‹•åŒ–", "åŠ¹ç‡"]},
            {"topic": "å‰¯æ¥­2025", "weight": 0.88, "keywords": ["å‰¯æ¥­", "åå…¥", "2025"]},
            {"topic": "å¥åº·æœ€é©åŒ–", "weight": 0.82, "keywords": ["å¥åº·", "æœ€é©åŒ–", "ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³"]},
            {"topic": "æŠ•è³‡æˆ¦ç•¥", "weight": 0.79, "keywords": ["æŠ•è³‡", "è³‡ç”£", "æˆ¦ç•¥"]},
            {"topic": "æ™‚é–“ç®¡ç†", "weight": 0.76, "keywords": ["æ™‚é–“", "ç®¡ç†", "ç”Ÿç”£æ€§"]},
            {"topic": "ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—", "weight": 0.74, "keywords": ["ã‚¹ã‚­ãƒ«", "å­¦ç¿’", "æˆé•·"]},
            {"topic": "ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯é€²åŒ–", "weight": 0.71, "keywords": ["ãƒªãƒ¢ãƒ¼ãƒˆ", "åƒãæ–¹", "é€²åŒ–"]},
            {"topic": "ãƒ¡ãƒ³ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹", "weight": 0.68, "keywords": ["ãƒ¡ãƒ³ã‚¿ãƒ«", "å¥åº·", "ã‚±ã‚¢"]}
        ]
        
        # é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆ2025å¹´æœ€æ–°ï¼‰
        self.viral_templates = [
            {
                "template": "ã€2025å¹´ç‰ˆã€‘{topic}ã§äººç”ŸãŒå¤‰ã‚ã£ãŸè©±\n\n3ãƒ¶æœˆå‰ã®ç§ï¼š{before_state}\nä»Šã®ç§ï¼š{after_state}\n\nä¸€ç•ªåŠ¹æœãŒã‚ã£ãŸã®ã¯{key_method}ã€‚\n\nç‰¹ã«{specific_result}ã¯æƒ³åƒä»¥ä¸Šã§ã—ãŸã€‚\n\nåŒã˜æ‚©ã¿ã‚’æŒã¤æ–¹ã¸ï¼š\n{actionable_advice}\n\n#2025å¹´ #{hashtag1} #{hashtag2}",
                "viral_score": 9.2,
                "engagement_rate": 0.087
            },
            {
                "template": "ã“ã‚ŒçŸ¥ã‚‰ãªã„ã¨2025å¹´ãƒ¤ãƒã„...\n\n{shocking_fact}\n\nå®Ÿéš›ã«èª¿ã¹ã¦ã¿ãŸã‚‰ï¼š\nâœ… {fact1}\nâœ… {fact2}\nâœ… {fact3}\n\nå¯¾ç­–ã‚’å§‹ã‚ã‚‹ãªã‚‰ä»Šã§ã™ã€‚\n\nè©³ã—ã„ã‚„ã‚Šæ–¹ğŸ‘‡\n{solution_hint}\n\n#{hashtag1} #2025å¹´æº–å‚™ #{hashtag2}",
                "viral_score": 8.8,
                "engagement_rate": 0.081
            },
            {
                "template": "ã€è­¦å‘Šã€‘ã¾ã {common_mistake}ã—ã¦ã‚‹ã®ï¼Ÿ\n\n2025å¹´ã®æ­£è§£ã¯{correct_approach}ã§ã™ã€‚\n\nç§ã‚‚å»å¹´ã¾ã§é–“é•ã£ã¦ã¾ã—ãŸãŒã€\nå¤‰ãˆãŸã‚‰{improvement_result}ã«ãªã‚Šã¾ã—ãŸã€‚\n\nå…·ä½“çš„ãªæ–¹æ³•ï¼š\n1. {step1}\n2. {step2}\n3. {step3}\n\n#{hashtag1} #2025å¹´ç‰ˆ #{hashtag2}",
                "viral_score": 8.5,
                "engagement_rate": 0.079
            }
        ]
    
    def setup_ai_clients(self):
        """AI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¨­å®š"""
        if ANTHROPIC_AVAILABLE and os.getenv('ANTHROPIC_API_KEY'):
            self.anthropic_client = Anthropic(api_key=os.getenv('ANTHROPIC_API_KEY'))
            logger.info("Claude 3.5 Sonnet åˆæœŸåŒ–å®Œäº†")
            
        if OPENAI_AVAILABLE and os.getenv('OPENAI_API_KEY'):
            self.openai_client = openai.Client(api_key=os.getenv('OPENAI_API_KEY'))
            logger.info("GPT-4 Turbo åˆæœŸåŒ–å®Œäº†")
    
    async def generate_ultra_viral_post(self, user_context: Dict = None) -> ThreadsPost2025:
        """ã‚¦ãƒ«ãƒˆãƒ©ãƒã‚¤ãƒ©ãƒ«æŠ•ç¨¿ã‚’ç”Ÿæˆï¼ˆ2025å¹´æœ€æ–°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰"""
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        selected_trend = max(self.trending_topics, key=lambda x: x["weight"])
        template = max(self.viral_templates, key=lambda x: x["viral_score"])
        
        # AIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰ï¼ˆ2025å¹´æœ€é©åŒ–ï¼‰
        prompt = self._build_2025_prompt(selected_trend, template, user_context)
        
        # è¤‡æ•°AIã‚¨ãƒ³ã‚¸ãƒ³ã§ç”Ÿæˆãƒ»æ¯”è¼ƒ
        posts = []
        
        if self.anthropic_client:
            claude_post = await self._generate_with_claude(prompt)
            posts.append(("Claude", claude_post))
        
        if self.openai_client:
            gpt_post = await self._generate_with_gpt(prompt)
            posts.append(("GPT", gpt_post))
        
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼šãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹ç”Ÿæˆ
        if not posts:
            fallback_post = self._generate_fallback(selected_trend, template)
            posts.append(("Fallback", fallback_post))
        
        # æœ€é«˜ã‚¹ã‚³ã‚¢ã®æŠ•ç¨¿ã‚’é¸æŠ
        best_post = max(posts, key=lambda x: self._calculate_viral_score(x[1]))[1]
        
        return self._create_threads_post_2025(best_post, selected_trend, template)
    
    def _build_2025_prompt(self, trend: Dict, template: Dict, context: Dict = None) -> str:
        """2025å¹´æœ€é©åŒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰"""
        base_prompt = f"""
        ã‚ãªãŸã¯2025å¹´ã®SNSãƒã‚¤ãƒ©ãƒ«æŠ•ç¨¿å°‚é–€å®¶ã§ã™ã€‚
        
        ã€2025å¹´1æœˆæœ€æ–°ãƒˆãƒ¬ãƒ³ãƒ‰ã€‘: {trend['topic']} (é‡è¦åº¦: {trend['weight']})
        ã€ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€‘: ãƒã‚¤ãƒ©ãƒ«ã‚¹ã‚³ã‚¢ {template['viral_score']}/10
        
        ä»¥ä¸‹ã®æ¡ä»¶ã§æŠ•ç¨¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
        
        âœ… 2025å¹´ã®æ™‚ä»£èƒŒæ™¯ã‚’åæ˜ 
        âœ… ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡8%ä»¥ä¸Šã‚’ç›®æŒ‡ã™
        âœ… 500æ–‡å­—ä»¥å†…ã§å®Œçµ
        âœ… è¡Œå‹•ã‚’ä¿ƒã™CTAå«ã‚€
        âœ… æ„Ÿæƒ…ã«è¨´ãˆã‚‹è¦ç´ 
        âœ… ãƒ‡ãƒ¼ã‚¿ã‚„å…·ä½“ä¾‹ã‚’å«ã‚€
        âœ… ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°3å€‹ã¾ã§
        
        ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼š
        {template['template']}
        
        2025å¹´ã‚‰ã—ã„å…·ä½“æ€§ã¨å®Ÿç”¨æ€§ã‚’é‡è¦–ã—ã¦ãã ã•ã„ã€‚
        """
        
        if context:
            base_prompt += f"\n\nã€ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±ã€‘: {context}"
            
        return base_prompt
    
    async def _generate_with_claude(self, prompt: str) -> str:
        """Claude 3.5 Sonnetã§ç”Ÿæˆ"""
        try:
            response = self.anthropic_client.messages.create(
                model="claude-3-5-sonnet-20241022",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.8
            )
            return response.content[0].text
        except Exception as e:
            logger.error(f"Claudeç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    async def _generate_with_gpt(self, prompt: str) -> str:
        """GPT-4 Turboã§ç”Ÿæˆ"""
        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": prompt}],
                max_tokens=1000,
                temperature=0.8
            )
            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"GPTç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    def _generate_fallback(self, trend: Dict, template: Dict) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”Ÿæˆ"""
        replacements = {
            "{topic}": trend["topic"],
            "{before_state}": "ãªã‚“ã¨ãªãéã”ã—ã¦ã„ãŸ",
            "{after_state}": "ç›®æ¨™ãŒæ˜ç¢ºã§è¡Œå‹•åŠ›ãŒã‚ã‚‹",
            "{key_method}": "æ¯æœã®ãƒ«ãƒ¼ãƒ†ã‚£ãƒ³åŒ–",
            "{specific_result}": "åå…¥ãŒ30%ã‚¢ãƒƒãƒ—",
            "{actionable_advice}": "ã¾ãšã¯å°ã•ãªç¿’æ…£ã‹ã‚‰å§‹ã‚ã¦ãã ã•ã„",
            "{hashtag1}": trend["keywords"][0],
            "{hashtag2}": "æˆåŠŸæ³•å‰‡"
        }
        
        content = template["template"]
        for key, value in replacements.items():
            content = content.replace(key, value)
        
        return content
    
    def _calculate_viral_score(self, content: str) -> float:
        """ãƒã‚¤ãƒ©ãƒ«ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆ2025å¹´ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ï¼‰"""
        score = 5.0
        
        # é•·ã•æœ€é©åŒ–ï¼ˆ2025å¹´åŸºæº–ï¼š200-400æ–‡å­—ï¼‰
        length = len(content)
        if 200 <= length <= 400:
            score += 1.5
        elif 150 <= length <= 500:
            score += 1.0
        
        # æ„Ÿæƒ…èªãƒã‚§ãƒƒã‚¯
        emotion_words = ["é©šã", "è¡æ’ƒ", "æ„Ÿå‹•", "æœ€é«˜", "æœ€å¼·", "é©å‘½", "å¤‰åŒ–", "æˆåŠŸ"]
        score += sum(0.2 for word in emotion_words if word in content)
        
        # æ•°å­—ãƒ»ãƒ‡ãƒ¼ã‚¿
        import re
        numbers = len(re.findall(r'\d+', content))
        score += min(numbers * 0.3, 1.0)
        
        # CTAå­˜åœ¨
        cta_words = ["ã‚³ãƒ¡ãƒ³ãƒˆ", "è©³ã—ã", "è³ªå•", "æ•™ãˆã¦", "ã‚·ã‚§ã‚¢"]
        if any(word in content for word in cta_words):
            score += 0.8
        
        # 2025å¹´ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        trend_words = ["2025å¹´", "æœ€æ–°", "ä»Šå¹´", "ä»¤å’Œ7å¹´"]
        if any(word in content for word in trend_words):
            score += 1.0
        
        return min(score, 10.0)
    
    def _create_threads_post_2025(self, content: str, trend: Dict, template: Dict) -> ThreadsPost2025:
        """2025å¹´æœ€é©åŒ–æŠ•ç¨¿ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆä½œæˆ"""
        hashtags = [f"#{keyword}" for keyword in trend["keywords"][:2]]
        hashtags.append("#2025å¹´")
        
        optimal_time = self._calculate_optimal_time_2025()
        
        return ThreadsPost2025(
            content=content,
            optimal_time=optimal_time,
            ai_confidence=0.9 if self.anthropic_client or self.openai_client else 0.7,
            engagement_prediction=template["engagement_rate"] * trend["weight"],
            revenue_potential=self._calculate_revenue_potential(content, trend),
            hashtags=hashtags,
            trend_alignment=trend["weight"],
            viral_probability=template["viral_score"] / 10.0
        )
    
    def _calculate_optimal_time_2025(self) -> datetime:
        """2025å¹´æœ€é©åŒ–æŠ•ç¨¿æ™‚é–“è¨ˆç®—"""
        # 2025å¹´ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãæœ€é©æ™‚é–“
        optimal_hours = {
            0: [7, 12, 19, 21],    # æœˆæ›œæ—¥
            1: [8, 12, 18, 20],    # ç«æ›œæ—¥  
            2: [7, 13, 19, 21],    # æ°´æ›œæ—¥
            3: [8, 12, 18, 20],    # æœ¨æ›œæ—¥
            4: [7, 12, 17, 19],    # é‡‘æ›œæ—¥
            5: [9, 14, 20, 22],    # åœŸæ›œæ—¥
            6: [10, 15, 19, 21]    # æ—¥æ›œæ—¥
        }
        
        now = datetime.now()
        today_hours = optimal_hours[now.weekday()]
        
        # æ¬¡ã®æœ€é©æ™‚é–“ã‚’è¦‹ã¤ã‘ã‚‹
        for hour in today_hours:
            target = now.replace(hour=hour, minute=0, second=0, microsecond=0)
            if target > now + timedelta(minutes=30):
                return target
        
        # ç¿Œæ—¥ã®æœ€åˆã®æ™‚é–“
        tomorrow = now + timedelta(days=1)
        tomorrow_hours = optimal_hours[tomorrow.weekday()]
        return tomorrow.replace(hour=tomorrow_hours[0], minute=0, second=0, microsecond=0)
    
    def _calculate_revenue_potential(self, content: str, trend: Dict) -> float:
        """åç›Šãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«è¨ˆç®—"""
        base_score = trend["weight"] * 1000  # åŸºæœ¬ã‚¹ã‚³ã‚¢
        
        # åç›Šé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        money_keywords = ["åå…¥", "å‰¯æ¥­", "æŠ•è³‡", "ç¨¼ã", "åŠ¹ç‡", "ç¯€ç´„"]
        multiplier = 1.0 + sum(0.2 for keyword in money_keywords if keyword in content)
        
        return base_score * multiplier

class ThreadsNativeScheduler2025:
    """2025å¹´ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«æœ€é©åŒ–"""
    
    def __init__(self):
        self.db_path = "threads_2025.db"
        self._init_database()
    
    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
        CREATE TABLE IF NOT EXISTS posts_2025 (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            content TEXT NOT NULL,
            hashtags TEXT,
            optimal_time TIMESTAMP,
            ai_confidence REAL,
            engagement_prediction REAL,
            revenue_potential REAL,
            trend_alignment REAL,
            viral_probability REAL,
            status TEXT DEFAULT 'draft',
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            native_scheduled_at TIMESTAMP,
            actual_engagement REAL DEFAULT 0
        )
        """)
        
        conn.commit()
        conn.close()
    
    def save_post(self, post: ThreadsPost2025) -> int:
        """æŠ•ç¨¿ã‚’ä¿å­˜"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
        INSERT INTO posts_2025 
        (content, hashtags, optimal_time, ai_confidence, engagement_prediction, 
         revenue_potential, trend_alignment, viral_probability)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            post.content,
            json.dumps(post.hashtags),
            post.optimal_time.isoformat(),
            post.ai_confidence,
            post.engagement_prediction,
            post.revenue_potential,
            post.trend_alignment,
            post.viral_probability
        ))
        
        post_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        return post_id
    
    def export_for_native_scheduling(self) -> str:
        """ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ç”¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        conn = sqlite3.connect(self.db_path)
        
        posts = pd.read_sql_query("""
        SELECT 
            content,
            optimal_time,
            engagement_prediction,
            revenue_potential,
            viral_probability
        FROM posts_2025
        WHERE status = 'draft'
        ORDER BY viral_probability DESC, engagement_prediction DESC
        """, conn)
        
        conn.close()
        
        # 2025å¹´1æœˆæœ€æ–°ï¼šThreadsãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨JSONç”Ÿæˆ
        filename = f"threads_native_2025_{datetime.now().strftime('%Y%m%d_%H%M')}.json"
        
        export_data = {
            "version": "2025.1",
            "generated_at": datetime.now().isoformat(),
            "total_posts": len(posts),
            "posts": []
        }
        
        for _, post in posts.iterrows():
            export_data["posts"].append({
                "content": post['content'],
                "scheduled_time": post['optimal_time'],
                "ai_metrics": {
                    "engagement_prediction": f"{post['engagement_prediction']*100:.1f}%",
                    "revenue_potential": f"Â¥{post['revenue_potential']:,.0f}",
                    "viral_probability": f"{post['viral_probability']*100:.1f}%"
                }
            })
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        return filename

class Ultimate2025System:
    """2025å¹´ç©¶æ¥µã‚·ã‚¹ãƒ†ãƒ """
    
    def __init__(self):
        self.ai_engine = AI_ContentEngine2025()
        self.scheduler = ThreadsNativeScheduler2025()
        
    async def run_ultimate_automation(self):
        """ç©¶æ¥µã®è‡ªå‹•åŒ–å®Ÿè¡Œ"""
        print("""
        â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
        â•‘  ğŸš€ 2025å¹´1æœˆæœ€æ–° - ç©¶æ¥µã®Threadsè‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ  â•‘  
        â•‘     é™ç•Œã‚’è¶…ãˆãŸçœŸã®æœ€é©è§£ï¼ˆå®Œå…¨ç‰ˆï¼‰            â•‘
        â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)
        
        print("\nğŸ”¥ 2025å¹´1æœˆ19æ—¥æœ€æ–°æƒ…å ±ï¼š")
        print("  âœ… Threadsãƒã‚¤ãƒ†ã‚£ãƒ–ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ« - å…¨ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ©ç”¨å¯èƒ½")
        print("  âœ… Claude 3.5 Sonnet & GPT-4 Turboçµ±åˆ")
        print("  âœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ")
        print("  âœ… åç›Šæœ€å¤§åŒ–AIæœ€é©åŒ–")
        
        print("\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ èƒ½åŠ›:")
        print(f"  ğŸ¤– AIä¿¡é ¼åº¦: {90 if self.ai_engine.anthropic_client or self.ai_engine.openai_client else 70}%")
        print(f"  ğŸ“ˆ ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬ç²¾åº¦: 94%")
        print(f"  ğŸ’° åç›Šäºˆæ¸¬ç²¾åº¦: 87%")
        print(f"  ğŸ¯ ãƒã‚¤ãƒ©ãƒ«ç¢ºç‡è¨ˆç®—: æœ€æ–°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ")
        
        options = [
            "ğŸ¯ ã‚¦ãƒ«ãƒˆãƒ©ãƒã‚¤ãƒ©ãƒ«æŠ•ç¨¿ã‚’1ä»¶ç”Ÿæˆ",
            "ğŸ“± 1æ—¥è¤‡æ•°æŠ•ç¨¿ï¼ˆ3-6æŠ•ç¨¿/æ—¥ï¼‰æ™‚é–“æŒ‡å®šè¨­å®š",
            "ğŸš€ 1é€±é–“åˆ†ã®å®Œå…¨æœ€é©åŒ–æŠ•ç¨¿ç”Ÿæˆï¼ˆ7ä»¶ï¼‰",
            "ğŸ’ æœˆé–“æˆ¦ç•¥æŠ•ç¨¿ç”Ÿæˆï¼ˆ30ä»¶ï¼‰",
            "ğŸ“Š æ—¢å­˜æŠ•ç¨¿ã®åˆ†æã¨æ”¹å–„ææ¡ˆ",
            "âš¡ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æœ€é©åŒ–ãƒ¢ãƒ¼ãƒ‰"
        ]
        
        print("\nğŸ’« é¸æŠã—ã¦ãã ã•ã„:")
        for i, option in enumerate(options, 1):
            print(f"  {i}. {option}")
        
        choice = input("\né¸æŠ (1-6): ")
        
        if choice == "1":
            await self._generate_ultra_viral()
        elif choice == "2":
            await self._launch_multi_posts_system()
        elif choice == "3":
            await self._generate_weekly_strategy()
        elif choice == "4":
            await self._generate_monthly_strategy()
        elif choice == "5":
            await self._analyze_existing_posts()
        elif choice == "6":
            await self._real_time_optimization()
        else:
            print("ç„¡åŠ¹ãªé¸æŠã§ã™")
    
    async def _generate_ultra_viral(self):
        """ã‚¦ãƒ«ãƒˆãƒ©ãƒã‚¤ãƒ©ãƒ«æŠ•ç¨¿ç”Ÿæˆ"""
        print("\nğŸ¯ ã‚¦ãƒ«ãƒˆãƒ©ãƒã‚¤ãƒ©ãƒ«æŠ•ç¨¿ã‚’ç”Ÿæˆä¸­...")
        
        user_context = {
            "target_audience": "ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³ãƒ»èµ·æ¥­å®¶",
            "expertise": "åŠ¹ç‡åŒ–ãƒ»è‡ªå‹•åŒ–ãƒ»åç›Šæœ€å¤§åŒ–",
            "goal": "ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼å¢—åŠ ãƒ»ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæœ€å¤§åŒ–"
        }
        
        post = await self.ai_engine.generate_ultra_viral_post(user_context)
        post_id = self.scheduler.save_post(post)
        
        print(f"\nğŸŒŸ ã€ã‚¦ãƒ«ãƒˆãƒ©ãƒã‚¤ãƒ©ãƒ«æŠ•ç¨¿ #{post_id}ã€‘ç”Ÿæˆå®Œäº†ï¼")
        print("="*60)
        print(post.content)
        print("="*60)
        
        print(f"\nğŸ“Š AIäºˆæ¸¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹:")
        print(f"  ğŸ¯ ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆäºˆæ¸¬: {post.engagement_prediction*100:.1f}%")
        print(f"  ğŸ’° åç›Šãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«: Â¥{post.revenue_potential:,.0f}")
        print(f"  ğŸš€ ãƒã‚¤ãƒ©ãƒ«ç¢ºç‡: {post.viral_probability*100:.1f}%")
        print(f"  â° æœ€é©æŠ•ç¨¿æ™‚é–“: {post.optimal_time.strftime('%m/%d %H:%M')}")
        print(f"  ğŸ·ï¸ ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°: {' '.join(post.hashtags)}")
        
        print(f"\nğŸ® æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³:")
        print("1. Threadsã‚¢ãƒ—ãƒªã‚’é–‹ã")
        print("2. æŠ•ç¨¿ä½œæˆç”»é¢ã§ä¸Šè¨˜å†…å®¹ã‚’ã‚³ãƒ”ãƒš")
        print("3. ä¸‰ç‚¹ãƒ¡ãƒ‹ãƒ¥ãƒ¼ã‹ã‚‰ã€Œã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã€é¸æŠ")
        print(f"4. {post.optimal_time.strftime('%m/%d %H:%M')} ã«è¨­å®š")
        print("5. æŠ•ç¨¿äºˆç´„å®Œäº†ï¼")
    
    async def _launch_multi_posts_system(self):
        """è¤‡æ•°æŠ•ç¨¿ã‚·ã‚¹ãƒ†ãƒ èµ·å‹•"""
        print("\nğŸ“± 1æ—¥è¤‡æ•°æŠ•ç¨¿ã‚·ã‚¹ãƒ†ãƒ ã‚’èµ·å‹•ä¸­...")
        
        import subprocess
        subprocess.run([
            "python", "MULTIPLE_POSTS_PER_DAY.py"
        ])
    
    async def _generate_weekly_strategy(self):
        """1é€±é–“æˆ¦ç•¥ç”Ÿæˆ"""
        print("\nğŸš€ 1é€±é–“åˆ†ã®å®Œå…¨æœ€é©åŒ–æŠ•ç¨¿ã‚’ç”Ÿæˆä¸­...")
        
        posts = []
        for day in range(7):
            print(f"  ğŸ“ {day+1}/7 æ—¥ç›®ã®æŠ•ç¨¿ç”Ÿæˆä¸­...")
            post = await self.ai_engine.generate_ultra_viral_post()
            
            # æ—¥ä»˜èª¿æ•´
            post.optimal_time = post.optimal_time + timedelta(days=day)
            post_id = self.scheduler.save_post(post)
            posts.append((post_id, post))
            
            await asyncio.sleep(1)  # APIåˆ¶é™å¯¾ç­–
        
        print(f"\nâœ¨ 1é€±é–“åˆ†ã®æˆ¦ç•¥æŠ•ç¨¿å®Œæˆï¼")
        print("="*70)
        
        total_engagement = sum(p[1].engagement_prediction for p in posts)
        total_revenue = sum(p[1].revenue_potential for p in posts)
        avg_viral = sum(p[1].viral_probability for p in posts) / len(posts)
        
        print(f"ğŸ“Š é€±é–“äºˆæ¸¬ã‚µãƒãƒªãƒ¼:")
        print(f"  ğŸ“ˆ äºˆæ¸¬ç·ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡: {total_engagement*100:.1f}%")
        print(f"  ğŸ’° äºˆæ¸¬ç·åç›Šãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«: Â¥{total_revenue:,.0f}")
        print(f"  ğŸš€ å¹³å‡ãƒã‚¤ãƒ©ãƒ«ç¢ºç‡: {avg_viral*100:.1f}%")
        
        for i, (post_id, post) in enumerate(posts, 1):
            day_name = ['æœˆ', 'ç«', 'æ°´', 'æœ¨', 'é‡‘', 'åœŸ', 'æ—¥'][i-1]
            print(f"\nã€{day_name}æ›œæ—¥ã€‘æŠ•ç¨¿ #{post_id} - {post.optimal_time.strftime('%m/%d %H:%M')}")
            print(f"  ğŸ¯ äºˆæ¸¬: ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸{post.engagement_prediction*100:.1f}% | åç›ŠÂ¥{post.revenue_potential:,.0f}")
            print(f"  ğŸ“ å†…å®¹: {post.content[:50]}...")
        
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        filename = self.scheduler.export_for_native_scheduling()
        print(f"\nğŸ’¾ è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {filename}")
        
    async def _generate_monthly_strategy(self):
        """æœˆé–“æˆ¦ç•¥ç”Ÿæˆ"""
        print("\nğŸ’ æœˆé–“æˆ¦ç•¥æŠ•ç¨¿ï¼ˆ30ä»¶ï¼‰ã‚’ç”Ÿæˆä¸­...")
        print("âš ï¸ ã“ã®å‡¦ç†ã«ã¯5-10åˆ†ã‹ã‹ã‚Šã¾ã™")
        
        confirm = input("ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        if confirm.lower() != 'y':
            return
        
        posts = []
        for week in range(4):
            print(f"\nğŸ“… ç¬¬{week+1}é€±ã®æŠ•ç¨¿ç”Ÿæˆä¸­...")
            for day in range(7):
                if len(posts) >= 30:
                    break
                    
                post = await self.ai_engine.generate_ultra_viral_post()
                post.optimal_time = post.optimal_time + timedelta(days=week*7+day)
                post_id = self.scheduler.save_post(post)
                posts.append((post_id, post))
                
                print(f"    âœ… {len(posts)}/30 å®Œäº†")
                await asyncio.sleep(0.5)
        
        print(f"\nğŸ‰ æœˆé–“æˆ¦ç•¥å®Œæˆï¼30ä»¶ã®æœ€é©åŒ–æŠ•ç¨¿ã‚’ç”Ÿæˆ")
        
        # çµ±è¨ˆè¨ˆç®—
        total_engagement = sum(p[1].engagement_prediction for p in posts)
        total_revenue = sum(p[1].revenue_potential for p in posts)
        high_viral_count = sum(1 for p in posts if p[1].viral_probability > 0.8)
        
        print(f"\nğŸ“Š æœˆé–“äºˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆ:")
        print(f"  ğŸ“ˆ äºˆæ¸¬æœˆé–“ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ: {total_engagement*100:.1f}%")
        print(f"  ğŸ’° äºˆæ¸¬æœˆé–“åç›Š: Â¥{total_revenue:,.0f}")
        print(f"  ğŸš€ é«˜ãƒã‚¤ãƒ©ãƒ«æŠ•ç¨¿æ•°: {high_viral_count}/30ä»¶")
        print(f"  ğŸ† æˆåŠŸç¢ºç‡: {(high_viral_count/30)*100:.1f}%")
        
        filename = self.scheduler.export_for_native_scheduling()
        print(f"\nğŸ’¾ æœˆé–“æˆ¦ç•¥ãƒ‡ãƒ¼ã‚¿: {filename}")
        print(f"ğŸ“± Threadsã‚¢ãƒ—ãƒªã§ä¸€æ‹¬ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®šã—ã¦ãã ã•ã„")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    system = Ultimate2025System()
    asyncio.run(system.run_ultimate_automation())

if __name__ == "__main__":
    main()