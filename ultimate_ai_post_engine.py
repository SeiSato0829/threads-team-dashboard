#!/usr/bin/env python3
"""
ç©¶æ¥µã®Threads AIè‡ªå‹•æŠ•ç¨¿ã‚¨ãƒ³ã‚¸ãƒ³
é«˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’åˆ†æã—ã€AIã§æ–°ã—ã„æŠ•ç¨¿ã‚’è‡ªå‹•ç”Ÿæˆãƒ»æŠ•ç¨¿ã™ã‚‹
"""

import os
import json
import random
import asyncio
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any
import openai
from dotenv import load_dotenv
import sqlite3
import re
import requests
from collections import Counter
import numpy as np

load_dotenv()

class UltimateThreadsAIEngine:
    def __init__(self):
        self.db_path = "threads_auto_post.db"
        self.templates_path = "money_optimization_sheets/02_é«˜åç›Šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ.tsv"
        self.engagement_threshold = 0.05  # 5%ä»¥ä¸Šã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.claude_api_key = os.getenv('CLAUDE_API_KEY')
        self.threads_api_token = os.getenv('THREADS_API_TOKEN')
        
    def analyze_high_engagement_patterns(self) -> Dict[str, Any]:
        """é«˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        conn = sqlite3.connect(self.db_path)
        
        # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿ã‚’å–å¾—
        query = """
        SELECT content, likes, comments, reposts, impressions,
               (likes + comments + reposts) * 1.0 / NULLIF(impressions, 0) as engagement_rate
        FROM posts
        WHERE impressions > 100
        ORDER BY engagement_rate DESC
        LIMIT 50
        """
        
        df = pd.read_sql_query(query, conn)
        conn.close()
        
        patterns = {
            'emoji_usage': self._analyze_emoji_patterns(df),
            'content_structure': self._analyze_content_structure(df),
            'keywords': self._extract_high_performing_keywords(df),
            'content_length': self._analyze_content_length(df),
            'hashtag_patterns': self._analyze_hashtag_patterns(df),
            'cta_patterns': self._analyze_cta_patterns(df)
        }
        
        return patterns
    
    def _analyze_emoji_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:
        """çµµæ–‡å­—ã®ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        emoji_pattern = re.compile(r'[^\u0000-\u007F\u0080-\u00FF\u2000-\u206F]+')
        emoji_counts = Counter()
        
        for content in df['content']:
            emojis = emoji_pattern.findall(content)
            emoji_counts.update(emojis)
        
        return {
            'top_emojis': emoji_counts.most_common(10),
            'avg_emoji_count': np.mean([len(emoji_pattern.findall(c)) for c in df['content']])
        }
    
    def _analyze_content_structure(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„æ§‹é€ ã‚’åˆ†æ"""
        structures = []
        
        for content in df['content']:
            structure = {
                'has_numbered_list': bool(re.search(r'\d+\.', content)),
                'has_bullet_points': 'ãƒ»' in content or 'âœ…' in content,
                'has_question': 'ï¼Ÿ' in content or '?' in content,
                'line_count': len(content.split('\n')),
                'has_cta': any(cta in content for cta in ['è©³ç´°ã¯', 'ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«', 'DM', 'ã‚³ãƒ¡ãƒ³ãƒˆ'])
            }
            structures.append(structure)
        
        return pd.DataFrame(structures).mean().to_dict()
    
    def _extract_high_performing_keywords(self, df: pd.DataFrame) -> List[str]:
        """é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŠ½å‡º"""
        all_words = []
        
        for content in df['content']:
            # æ—¥æœ¬èªã®å˜èªã‚’æŠ½å‡ºï¼ˆç°¡æ˜“çš„ãªæ–¹æ³•ï¼‰
            words = re.findall(r'[ã-ã‚“ã‚¡-ãƒ¶ãƒ¼ä¸€-é¾ ]+', content)
            all_words.extend(words)
        
        word_counts = Counter(all_words)
        # 2æ–‡å­—ä»¥ä¸Šã®é »å‡ºå˜èªä¸Šä½20å€‹
        return [word for word, count in word_counts.most_common(50) if len(word) >= 2][:20]
    
    def _analyze_content_length(self, df: pd.DataFrame) -> Dict[str, float]:
        """ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã®é•·ã•ã‚’åˆ†æ"""
        lengths = [len(content) for content in df['content']]
        return {
            'avg_length': np.mean(lengths),
            'optimal_range': (np.percentile(lengths, 25), np.percentile(lengths, 75))
        }
    
    def _analyze_hashtag_patterns(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        hashtags = []
        
        for content in df['content']:
            tags = re.findall(r'#[^\s]+', content)
            hashtags.extend(tags)
        
        return {
            'popular_hashtags': Counter(hashtags).most_common(10),
            'avg_hashtag_count': np.mean([len(re.findall(r'#[^\s]+', c)) for c in df['content']])
        }
    
    def _analyze_cta_patterns(self, df: pd.DataFrame) -> List[str]:
        """CTAï¼ˆCall to Actionï¼‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ"""
        cta_patterns = [
            r'è©³ç´°ã¯.*ãƒªãƒ³ã‚¯',
            r'DM.*å—ä»˜',
            r'ã‚³ãƒ¡ãƒ³ãƒˆ.*ãã ã•ã„',
            r'ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«.*ã‹ã‚‰',
            r'ä¿å­˜.*ãã ã•ã„',
            r'ã„ã„ã­.*ãŠé¡˜ã„'
        ]
        
        found_ctas = []
        for content in df['content']:
            for pattern in cta_patterns:
                if re.search(pattern, content):
                    match = re.search(pattern, content)
                    found_ctas.append(match.group())
        
        return list(set(found_ctas))[:10]
    
    async def generate_ai_post(self, topic: str, patterns: Dict[str, Any]) -> str:
        """AIã§æ–°ã—ã„æŠ•ç¨¿ã‚’ç”Ÿæˆ"""
        # é«˜åç›Šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿
        templates_df = pd.read_csv(self.templates_path, sep='\t')
        
        # ãƒ©ãƒ³ãƒ€ãƒ ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é¸æŠ
        template_row = templates_df.sample(1).iloc[0]
        template = template_row['ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå†…å®¹']
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        prompt = f"""
        ä»¥ä¸‹ã®åˆ†æçµæœã‚’å‚è€ƒã«ã€Threadsã§é«˜ã„ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’ç²å¾—ã§ãã‚‹æŠ•ç¨¿ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚

        ã€ãƒˆãƒ”ãƒƒã‚¯ã€‘: {topic}
        
        ã€ä½¿ç”¨ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã€‘:
        {template}
        
        ã€é«˜ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŠ•ç¨¿ã®ç‰¹å¾´ã€‘:
        - å¹³å‡æ–‡å­—æ•°: {patterns['content_length']['avg_length']:.0f}æ–‡å­—
        - äººæ°—ã®çµµæ–‡å­—: {', '.join([e[0] for e in patterns['emoji_usage']['top_emojis'][:5]])}
        - å¹³å‡çµµæ–‡å­—æ•°: {patterns['emoji_usage']['avg_emoji_count']:.1f}å€‹
        - ç•ªå·ä»˜ããƒªã‚¹ãƒˆä½¿ç”¨ç‡: {patterns['content_structure']['has_numbered_list']*100:.0f}%
        - ç®‡æ¡æ›¸ãä½¿ç”¨ç‡: {patterns['content_structure']['has_bullet_points']*100:.0f}%
        - è³ªå•å½¢å¼ä½¿ç”¨ç‡: {patterns['content_structure']['has_question']*100:.0f}%
        - åŠ¹æœçš„ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(patterns['keywords'][:10])}
        - äººæ°—ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°: {', '.join([h[0] for h in patterns['hashtag_patterns']['popular_hashtags'][:5]])}
        
        ã€ãƒ«ãƒ¼ãƒ«ã€‘:
        1. ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®{å¤‰æ•°}éƒ¨åˆ†ã‚’é©åˆ‡ã«åŸ‹ã‚ã‚‹
        2. è‡ªç„¶ã§èª­ã¿ã‚„ã™ã„æ—¥æœ¬èªã‚’ä½¿ç”¨
        3. ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’ä¿ƒã™è¦ç´ ã‚’å«ã‚ã‚‹
        4. 500æ–‡å­—ä»¥å†…ã§åã‚ã‚‹
        5. æœ€å¾Œã«é©åˆ‡ãªCTAã‚’å«ã‚ã‚‹
        
        æŠ•ç¨¿æ–‡ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ï¼š
        """
        
        # OpenAI APIã§ç”Ÿæˆ
        if self.openai_api_key:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯é«˜ã„ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆã‚’ç²å¾—ã™ã‚‹SNSæŠ•ç¨¿ã®å°‚é–€å®¶ã§ã™ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=500
            )
            return response.choices[0].message.content
        
        # Claude APIã§ç”Ÿæˆï¼ˆOpenAIãŒãªã„å ´åˆï¼‰
        elif self.claude_api_key:
            # Claude APIå®Ÿè£…
            pass
        
        # ãƒ‡ãƒ¢ç”¨ã®ãƒ€ãƒŸãƒ¼ç”Ÿæˆ
        return self._generate_demo_post(topic, template, patterns)
    
    def _generate_demo_post(self, topic: str, template: str, patterns: Dict[str, Any]) -> str:
        """ãƒ‡ãƒ¢ç”¨ã®æŠ•ç¨¿ã‚’ç”Ÿæˆ"""
        # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å¤‰æ•°ã‚’ç½®æ›
        replacements = {
            '{topic}': topic,
            '{method1}': 'ç«¶åˆåˆ†æã®å¾¹åº•',
            '{method2}': 'ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®æ´»ç”¨',
            '{method3}': 'A/Bãƒ†ã‚¹ãƒˆã®å®Ÿæ–½',
            '{result}': 'å£²ä¸ŠãŒ2.5å€ã«å¢—åŠ ',
            '{mistake}': f'{topic}ã§ã®å¤±æ•—',
            '{truth}': 'åŸºæœ¬ã‚’æŠ¼ã•ãˆã‚‹ã“ã¨ãŒæœ€é‡è¦',
            '{struggle}': 'æœˆ10ä¸‡å††ã®å£²ä¸Šã§åœæ»',
            '{number}': '5',
            '{skill}': topic,
            '{point1}': 'å¸‚å ´èª¿æŸ»',
            '{point2}': 'ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨­å®š',
            '{point3}': 'å·®åˆ¥åŒ–æˆ¦ç•¥',
            '{benefit}': 'ç¢ºå®Ÿã«æˆæœã‚’å‡ºã™'
        }
        
        post = template
        for key, value in replacements.items():
            post = post.replace(key, value)
        
        # äººæ°—ã®çµµæ–‡å­—ã‚’è¿½åŠ 
        popular_emojis = [e[0] for e in patterns['emoji_usage']['top_emojis'][:3]]
        if popular_emojis:
            post += '\n\n' + ' '.join(popular_emojis)
        
        # ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°ã‚’è¿½åŠ 
        hashtags = [h[0] for h in patterns['hashtag_patterns']['popular_hashtags'][:4]]
        if hashtags:
            post += '\n\n' + ' '.join(hashtags)
        
        return post
    
    async def schedule_and_post(self, content: str, scheduled_time: datetime = None):
        """æŠ•ç¨¿ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã—ã¦å®Ÿè¡Œ"""
        if not scheduled_time:
            # æœ€é©ãªæŠ•ç¨¿æ™‚é–“ã‚’é¸æŠï¼ˆæœ7æ™‚ã€æ˜¼12æ™‚ã€å¤œ19æ™‚ã€21æ™‚ï¼‰
            optimal_hours = [7, 12, 19, 21]
            now = datetime.now()
            
            # æ¬¡ã®æœ€é©ãªæ™‚é–“ã‚’è¦‹ã¤ã‘ã‚‹
            for hour in optimal_hours:
                scheduled = now.replace(hour=hour, minute=0, second=0)
                if scheduled > now:
                    scheduled_time = scheduled
                    break
            else:
                # ç¿Œæ—¥ã®æœ€åˆã®æ™‚é–“
                scheduled_time = (now + timedelta(days=1)).replace(hour=optimal_hours[0], minute=0, second=0)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute("""
        INSERT INTO scheduled_posts (content, scheduled_time, status, created_at)
        VALUES (?, ?, 'pending', ?)
        """, (content, scheduled_time.isoformat(), datetime.now().isoformat()))
        
        post_id = cursor.lastrowid
        conn.commit()
        conn.close()
        
        # å®Ÿéš›ã®æŠ•ç¨¿å‡¦ç†ï¼ˆThreads APIã‚’ä½¿ç”¨ï¼‰
        if self.threads_api_token:
            await self._post_to_threads(content, post_id)
        
        return {
            'post_id': post_id,
            'content': content,
            'scheduled_time': scheduled_time.isoformat(),
            'status': 'scheduled'
        }
    
    async def _post_to_threads(self, content: str, post_id: int):
        """Threads APIã§æŠ•ç¨¿"""
        # ã“ã“ã«Threads APIå®Ÿè£…
        # ç¾åœ¨ã¯ãƒ‡ãƒ¢ãªã®ã§å®Ÿè£…çœç•¥
        pass
    
    async def run_auto_generation_cycle(self, topics: List[str], posts_per_day: int = 3):
        """è‡ªå‹•ç”Ÿæˆã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œ"""
        print("ğŸš€ ç©¶æ¥µã®AIè‡ªå‹•æŠ•ç¨¿ã‚¨ãƒ³ã‚¸ãƒ³ã‚’èµ·å‹•ã—ã¾ã™...")
        
        # é«˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æ
        print("ğŸ“Š é«˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŠ•ç¨¿ã‚’åˆ†æä¸­...")
        patterns = self.analyze_high_engagement_patterns()
        
        print(f"âœ… åˆ†æå®Œäº†ï¼")
        print(f"   - äººæ°—ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {', '.join(patterns['keywords'][:5])}")
        print(f"   - æœ€é©æ–‡å­—æ•°: {patterns['content_length']['optimal_range']}")
        
        # å„ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦æŠ•ç¨¿ã‚’ç”Ÿæˆ
        generated_posts = []
        
        for topic in topics:
            print(f"\nğŸ¤– ã€Œ{topic}ã€ã«é–¢ã™ã‚‹æŠ•ç¨¿ã‚’ç”Ÿæˆä¸­...")
            
            # AIæŠ•ç¨¿ç”Ÿæˆ
            content = await self.generate_ai_post(topic, patterns)
            
            # æŠ•ç¨¿ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«
            result = await self.schedule_and_post(content)
            generated_posts.append(result)
            
            print(f"âœ… æŠ•ç¨¿ã‚’ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã—ã¾ã—ãŸ: {result['scheduled_time']}")
            print(f"ğŸ“ å†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼: {content[:50]}...")
        
        return generated_posts

# å®Ÿè¡Œç”¨ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
async def main():
    engine = UltimateThreadsAIEngine()
    
    # æŠ•ç¨¿ãƒˆãƒ”ãƒƒã‚¯ï¼ˆã‚ãªãŸã®ãƒ“ã‚¸ãƒã‚¹ã«åˆã‚ã›ã¦å¤‰æ›´ï¼‰
    topics = [
        "Webã‚µã‚¤ãƒˆåˆ¶ä½œã®åŠ¹ç‡åŒ–",
        "AIæ´»ç”¨ã§ã‚³ã‚¹ãƒˆå‰Šæ¸›",
        "ãƒ•ãƒªãƒ¼ãƒ©ãƒ³ã‚¹ã®æˆåŠŸæ³•å‰‡",
        "èµ·æ¥­å®¶ã®è³‡é‡‘èª¿é”",
        "ãƒ“ã‚¸ãƒã‚¹è‡ªå‹•åŒ–ãƒ„ãƒ¼ãƒ«"
    ]
    
    # è‡ªå‹•ç”Ÿæˆã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿè¡Œ
    results = await engine.run_auto_generation_cycle(topics, posts_per_day=3)
    
    print("\nğŸ‰ å…¨ã¦ã®æŠ•ç¨¿ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print(f"ğŸ“Š ç”Ÿæˆã•ã‚ŒãŸæŠ•ç¨¿æ•°: {len(results)}")

if __name__ == "__main__":
    asyncio.run(main())